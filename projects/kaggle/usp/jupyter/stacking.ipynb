{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gezi.common import *\n",
    "sys.path.append('..')\n",
    "from src.postprocess import *\n",
    "from src.config import *\n",
    "from src.eval import *\n",
    "from src.ensemble_conf import mns, get_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n",
       "...                 ...           ...                     ...     ...    ...\n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n",
       "36471  756ec035e694722b  wood article         wooden material     B44   0.75\n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gezi.init_flags()\n",
    "df = pd.read_csv(f'{FLAGS.root}/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': array(['00068e3dfd5515df', '000c8495ef1763e1', '0019b063a0fe1dc8', ...,\n",
       "        'ffb6e883de7d9d67', 'fff0b4d9fca7fae3', 'fff8d1ccce8e20ec'],\n",
       "       dtype='<U16'),\n",
       " 'label': array([0.25, 0.  , 0.  , ..., 0.5 , 0.25, 0.  ]),\n",
       " 'anchor': array(['conductor particles', 'page file', 'predetermined acceleration',\n",
       "        ..., 'water propulsion device',\n",
       "        'high gradient magnetic separators', 'perform working operations'],\n",
       "       dtype='<U38'),\n",
       " 'target': array(['resin cores', 'hidden camera', 'predetermined policy', ...,\n",
       "        'propulsion unit', 'magnetic equipment',\n",
       "        'psychology of working framework'], dtype='<U98'),\n",
       " 'text': array(['conductor particles[SEP]resin cores[SEP]PERFORMING OPERATIONS; TRANSPORTING. PHYSICAL OR CHEMICAL PROCESSES OR APPARATUS IN GENERAL[SEP]metal; conducting particles; gold tooth; transparent spheres particles; ballpen ink; sources; exchange membranes; electro conductive powders; source membranes; conductor fine particles; source electrodes; conductor; gold particles; metal cores; electric current; particles; copper particles; charged particle; talcum powder; conductive material; material particles; metal ornament; paper printing; conductor particle; fine particles; guides; conductors; conductive particle; transparent particles; gold ornament; metal particles; electro conductive particles; insulator granules; conductor material particles; conductive particles; spheres particles; spheres; exchange electrodes; transparent spheres; conductor powder',\n",
       "        'page file[SEP]hidden camera[SEP]PHYSICS. EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS[SEP]hidden system file; cache file; page description file; hard disk; sds page; file itr; document; page; paging memory; file converter; page break; main memory storage; data; data capture machine; memory; cache; additional address space; main dram; ram memory; fast space; main memory cache; page element; disk break; fast disk; system engineer; graphic cache; page memory; front file system; slow memory; paging file; page id; directory; fast memory; page monitoring',\n",
       "        'predetermined acceleration[SEP]predetermined policy[SEP]PERFORMING OPERATIONS; TRANSPORTING. HOISTING; LIFTING; HAULING[SEP]prearranged acceleration; limit; threshold; alternating accelerations; alternating acceleration; acceleration; speed; acceleration to acceleration; rapid acceleration; predetermined; acceleration system; predetermined deceleration; fixed acceleration; predetermined body weight; acceleration sensor; software acceleration program; undercarriage; sheave carrier; predetermined acceleration; respect to acceleration; given speed; predetermined speed; spooling device for drum cables; respect acceleration; acceleration accelerations; graphics acceleration; predetermined cost; predetermined rotational; displacement; predetermined threshold acceleration; predetermined first acceleration; preset acceleration; threshold speed; predetermined rotational speed; predetermined blood pressure; rapid accelerations; counterweight safety; accelerations; predetermined velocity',\n",
       "        ...,\n",
       "        'water propulsion device[SEP]propulsion unit[SEP]PERFORMING OPERATIONS; TRANSPORTING. SHIPS OR OTHER WATERBORNE VESSELS; RELATED EQUIPMENT[SEP]water jet propulsion unit; water propulsion; drive transmission; propeller propulsion wheels; propeller propulsion propeller; front transmission; duct lip; propulsion propeller; underwater propulsion device; rear wheel transmission; propulsion in maglev train; vehicle fuel tank position; fluid propulsion device; front wheel transmission; water rich fruits; charging device; magnus propeller; propulsion apparatus; water jet propulsion apparatus; propulsion wheel; water propulsion system; water propulsion device; life jacket; hybrid air cushion ground effect vehicle; propeller propulsion; front wheel unit; drive propeller; propulsion device; water jet propulsion system; drive wheel; inboard motor type; drive system; water jet propulsion; water jet propulsion device; water rich vegetables; water geyser; jet propulsion device; propulsion; propulsion system; eye water drop; marine propulsion device',\n",
       "        'high gradient magnetic separators[SEP]magnetic equipment[SEP]CHEMISTRY; METALLURGY. TREATMENT OF WATER, WASTE WATER, SEWAGE, OR SLUDGE[SEP]paramagnetic materials; hydrodynamic porous device; hgms; gradient magnetic separators; separator manufacturer; pressure vessel; color gradients; field gradient enhanced centrifugation; magnetic moment; membranes; separation by magnetic effect; separate magnetic materials; microporous polyolefin; electric field; high gradient magnetic extractor; clarifiers for separation; conveyor drum; photoelectric device; magnetic separator; ferritic material',\n",
       "        'perform working operations[SEP]psychology of working framework[SEP]PERFORMING OPERATIONS; TRANSPORTING. MACHINE TOOLS; METAL-WORKING NOT OTHERWISE PROVIDED FOR[SEP]working operations; stop working operations; implement work task; working principle; laser operation; terminate operations; job handling; implement working operations; performing cutting operation; perform working; perform metal working operations; clamping steel holder; working theory; perform working operation; perform cyclic operations; metal working operations; performing work operations; perform working action; perform operations; perform binary addition; execute working operation; operations research; perform working stroke; milling operation'],\n",
       "       dtype='<U2404'),\n",
       " 'context': array(['B01', 'G09', 'B66', ..., 'B63', 'C02', 'B23'], dtype='<U3'),\n",
       " 'fold': array([0, 0, 0, ..., 4, 4, 4]),\n",
       " 'pred': array([-2.1991644 , -5.6542377 , -5.6726756 , ...,  0.92332655,\n",
       "        -0.31666124, -6.1241155 ], dtype=float32),\n",
       " 'bert_proba': array([0.25278273, 0.02399713, 0.01598141, ..., 0.48638793, 0.3869513 ,\n",
       "        0.03204729])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "xs = []\n",
    "ensemblers = [gezi.Ensembler(need_sort=True, includes=['bert_proba']) for _ in range(FOLDS)]\n",
    "for model in mns:\n",
    "  for fold in range(FOLDS):\n",
    "    root = f'../working/offline/10/{fold}/{model}'\n",
    "    x = gezi.load(f'{root}/valid.pkl')\n",
    "    x['fold'] = np.asarray([fold] * len(x['id']))\n",
    "    x['bert_proba'] = normalize(x['pred'])\n",
    "    # xs.append(x)\n",
    "    ensemblers[fold].add(x, get_weight(model))\n",
    "xs = [ensembler.finalize() for ensembler in ensemblers]\n",
    "for x in xs:\n",
    "  x['bert_proba'] = normalize(x['bert_proba'])\n",
    "x = gezi.merge_array_dicts(xs)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['score'] = x['label']\n",
    "# x['bert_proba'] = normalize(x['bert_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x['text']\n",
    "del x['pred']\n",
    "del x['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8682403177522899"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(oof.score, oof.bert_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import time\n",
    "\n",
    "\n",
    "def run_stacking(train_data, test_data):\n",
    "    '''\n",
    "    Input:\n",
    "        train_data: [id, anchor, target, context, score, bert_proba, fold]\n",
    "        test_data: [id, anchor, target, context, bert_proba]\n",
    "    \n",
    "    Return:\n",
    "        X: ['id', 'score', 'bert_proba', 'tree_proba', 'stacking_proba']\n",
    "        X_test: ['id', 'bert_proba', 'tree_proba', 'stacking_proba']\n",
    "    '''\n",
    "    \n",
    "    FOLD = train_data['fold'].nunique()\n",
    "    \n",
    "    \n",
    "    def edit_distance(x, y):\n",
    "        len1 = len(x)\n",
    "        len2 = len(y)\n",
    "        dp = np.zeros((len1 + 1, len2 + 1))\n",
    "        for i in range(len1 + 1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(len2 + 1):\n",
    "            dp[0][j] = j\n",
    "        for i in range(1, len1 + 1):\n",
    "            for j in range(1, len2 + 1):\n",
    "                delta = 0 if x[i - 1] == y[j - 1] else 1\n",
    "                dp[i][j] = min(dp[i - 1][j - 1] + delta, min(dp[i - 1][j] + 1, dp[i][j - 1] + 1))\n",
    "        return dp[len1][len2]\n",
    "\n",
    "    def common_prefix_len(x, y):\n",
    "        min_len = min(len(x), len(y))\n",
    "        res = 0\n",
    "        for i in range(min_len):\n",
    "            if x[i] != y[i]:\n",
    "                break\n",
    "            res += 1\n",
    "        return res\n",
    "\n",
    "    def common_suffix_len(x, y):\n",
    "        min_len = min(len(x), len(y))\n",
    "        res = 0\n",
    "        for i in range(1, min_len + 1):\n",
    "            if x[-i] != y[-i]:\n",
    "                break\n",
    "            res += 1\n",
    "        return res\n",
    "\n",
    "    def LCStr(x, y):\n",
    "        len1 = len(x)\n",
    "        len2 = len(y)\n",
    "        record = [[0 for i in range(len2 + 1)] for j in range(len1 + 1)]\n",
    "        maxLen, p = 0, 0\n",
    "        for i in range(len1):\n",
    "            for j in range(len2):\n",
    "                if x[i] == y[j]:\n",
    "                    record[i + 1][j + 1] = record[i][j] + 1\n",
    "                    if record[i + 1][j + 1] > maxLen:\n",
    "                        maxLen = record[i + 1][j + 1]\n",
    "                        p = i + 1\n",
    "        return x[p - maxLen : p]\n",
    "\n",
    "    def head_common_index(x, y):\n",
    "        for i, j in enumerate(y):\n",
    "            if j == x[0]:\n",
    "                return i\n",
    "        return -1\n",
    "\n",
    "    def combine(x, y):\n",
    "        res = []\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                res.append(i + '_' + j)\n",
    "        return res\n",
    "    \n",
    "    def feat_eng_core(train_data, test_data):\n",
    "        train_data['tag'] = 0\n",
    "        test_data['tag'] = 1\n",
    "        df = pd.concat([train_data, test_data], axis=0, ignore_index=True)\n",
    "\n",
    "        df['context_code'] = df['context'].apply(lambda x: x[0])\n",
    "        df['context_num'] = df['context'].apply(lambda x: x[1:]).astype('int16')\n",
    "        \n",
    "        for f in tqdm(['anchor', 'context']):\n",
    "            df[f'{f}_count'] = df[f].map(df[f].value_counts())\n",
    "\n",
    "        df['anchor_context_count'] = df.groupby(['anchor', 'context'])['anchor'].transform('count')\n",
    "        df['anchor_in_context_count_prop'] = df['anchor_context_count'] / df['context_count']\n",
    "\n",
    "        df['anchor_in_context_nunique'] = df.groupby('context')['anchor'].transform('nunique')\n",
    "        df['anchor_in_context_nunique_count_ratio'] = df['anchor_in_context_nunique'] / df['context_count']\n",
    "\n",
    "        df['context_in_anchor_nunique'] = df.groupby('anchor')['context'].transform('nunique')\n",
    "        df['context_in_anchor_nunique_count_ratio'] = df['context_in_anchor_nunique'] / df['anchor_count']\n",
    "\n",
    "        df['anchor_context_code_count'] = df.groupby(['anchor', 'context_code'])['anchor'].transform('count')\n",
    "        df['anchor_in_context_code_nunique'] = df.groupby('context_code')['anchor'].transform('nunique')\n",
    "        df['context_code_in_anchor_nunique'] = df.groupby('anchor')['context_code'].transform('nunique')\n",
    "        \n",
    "        for f in tqdm(['anchor', 'target']):\n",
    "            df[f'{f}_char_list'] = df[f].apply(lambda x: list(x.replace(' ', '')))\n",
    "            df[f'{f}_word_list'] = df[f].apply(lambda x: x.split(' '))\n",
    "\n",
    "            df[f'{f}_char_set'] = df[f].apply(lambda x: set(x.replace(' ', '')))\n",
    "            df[f'{f}_word_set'] = df[f].apply(lambda x: set(x.split(' ')))\n",
    "\n",
    "            df[f'{f}_char_len'] = df[f'{f}_char_list'].apply(len)\n",
    "            df[f'{f}_word_len'] = df[f'{f}_word_list'].apply(len)\n",
    "\n",
    "        for f in tqdm(['char_len', 'word_len']):\n",
    "            df[f'{f}_diff'] = abs(df[f'anchor_{f}'] - df[f'target_{f}'])\n",
    "            df[f'{f}_diff_in_anchor_prop'] = df[f'{f}_diff'] / df[f'anchor_{f}']\n",
    "            df[f'{f}_diff_in_target_prop'] = df[f'{f}_diff'] / df[f'target_{f}']\n",
    "            df[f'{f}_ratio'] = df[f'anchor_{f}'] / df[f'target_{f}']\n",
    "\n",
    "        for f in tqdm(['char', 'word']):\n",
    "            df[f'{f}_inter'] = df[[f'anchor_{f}_set', f'target_{f}_set']].apply(\n",
    "                lambda x: len(x[f'anchor_{f}_set'] & x[f'target_{f}_set']), axis=1\n",
    "            )\n",
    "            df[f'{f}_union'] = df[[f'anchor_{f}_set', f'target_{f}_set']].apply(\n",
    "                lambda x: len(x[f'anchor_{f}_set'] | x[f'target_{f}_set']), axis=1\n",
    "            )\n",
    "            df[f'{f}_IoU'] = df[f'{f}_inter'] / df[f'{f}_union']\n",
    "        \n",
    "        df['char_edit_dist'] = df[['anchor_char_list', 'target_char_list']].apply(\n",
    "            lambda x: edit_distance(x['anchor_char_list'], x['target_char_list']), axis=1)\n",
    "        df['word_edit_dist'] = df[['anchor_word_list', 'target_word_list']].apply(\n",
    "            lambda x: edit_distance(x['anchor_word_list'], x['target_word_list']), axis=1)\n",
    "        \n",
    "        for f in tqdm(['char', 'word']):\n",
    "            df[f'{f}_common_prefix_len'] = df[[f'anchor_{f}_list', f'target_{f}_list']].apply(\n",
    "                lambda x: common_prefix_len(x[f'anchor_{f}_list'], x[f'target_{f}_list']), axis=1)\n",
    "            df[f'{f}_common_prefix'] = df[[f'anchor_{f}_list', f'{f}_common_prefix_len']].apply(\n",
    "                lambda x: ' '.join(x[f'anchor_{f}_list'][:x[f'{f}_common_prefix_len']])\n",
    "                          if x[f'{f}_common_prefix_len'] > 0 else '', axis=1\n",
    "            )\n",
    "\n",
    "            df[f'{f}_common_suffix_len'] = df[[f'anchor_{f}_list', f'target_{f}_list']].apply(\n",
    "                lambda x: common_suffix_len(x[f'anchor_{f}_list'], x[f'target_{f}_list']), axis=1)\n",
    "            df[f'{f}_common_suffix'] = df[[f'anchor_{f}_list', f'{f}_common_suffix_len']].apply(\n",
    "                lambda x: ' '.join(x[f'anchor_{f}_list'][-x[f'{f}_common_suffix_len']:])\n",
    "                          if x[f'{f}_common_suffix_len'] > 0 else '', axis=1\n",
    "            )\n",
    "\n",
    "            df[f'{f}_common_prefix_suffix_count'] = df.groupby(\n",
    "                [f'{f}_common_prefix', f'{f}_common_suffix'])['anchor'].transform('count')\n",
    "\n",
    "            df[f'{f}_LCStr'] = df[[f'anchor_{f}_list', f'target_{f}_list']].apply(\n",
    "                lambda x: LCStr(x[f'anchor_{f}_list'], x[f'target_{f}_list']), axis=1)\n",
    "            df[f'{f}_LCStr_len'] = df[f'{f}_LCStr'].apply(len)\n",
    "            df[f'{f}_LCStr'] = df[f'{f}_LCStr'].apply(''.join)\n",
    "            df[f'{f}_LCStr_count'] = df[f'{f}_LCStr'].map(df[f'{f}_LCStr'].value_counts())\n",
    "\n",
    "            df[f'anchor_in_target_{f}_head_common_index'] = df[[f'anchor_{f}_list', f'target_{f}_list']].apply(\n",
    "                lambda x: head_common_index(x[f'anchor_{f}_list'], x[f'target_{f}_list']), axis=1)\n",
    "            df[f'target_in_anchor_{f}_head_common_index'] = df[[f'anchor_{f}_list', f'target_{f}_list']].apply(\n",
    "                lambda x: head_common_index(x[f'target_{f}_list'], x[f'anchor_{f}_list']), axis=1)\n",
    "        \n",
    "        cate_cols = ['anchor', 'context', 'context_code']\n",
    "        for f in tqdm(['anchor', 'target']):\n",
    "            df[f'{f}_first_word'] = df[f'{f}_word_list'].apply(lambda x: x[0])\n",
    "            df[f'{f}_last_word'] = df[f'{f}_word_list'].apply(lambda x: x[-1])\n",
    "\n",
    "            df[f'{f}_first_word_count'] = df[f'{f}_first_word'].map(df[f'{f}_first_word'].value_counts())\n",
    "            df[f'{f}_last_word_count'] = df[f'{f}_last_word'].map(df[f'{f}_last_word'].value_counts())\n",
    "\n",
    "            cate_cols.extend([\n",
    "                f'{f}_first_word',\n",
    "                f'{f}_last_word'\n",
    "            ])\n",
    "\n",
    "        for f in tqdm(['word']):\n",
    "            df[f'first_{f}_count'] = df.groupby([f'anchor_first_{f}', f'target_first_{f}'])['anchor'].transform('count')\n",
    "            df[f'first_{f}_count_in_anchor_prop'] = df[f'first_{f}_count'] / df[f'anchor_first_{f}_count']\n",
    "            df[f'first_{f}_count_in_target_prop'] = df[f'first_{f}_count'] / df[f'target_first_{f}_count']\n",
    "\n",
    "            df[f'last_{f}_count'] = df.groupby([f'anchor_last_{f}', f'target_last_{f}'])['anchor'].transform('count')\n",
    "            df[f'last_{f}_count_in_anchor_prop'] = df[f'last_{f}_count'] / df[f'anchor_last_{f}_count']\n",
    "            df[f'last_{f}_count_in_target_prop'] = df[f'last_{f}_count'] / df[f'target_last_{f}_count']\n",
    "        \n",
    "        df['anchor_isin_target'] = df[['anchor', 'target']].apply(\n",
    "            lambda x: x['anchor'] in x['target'], axis=1).astype('int8')\n",
    "        df['target_isin_anchor'] = df[['anchor', 'target']].apply(\n",
    "            lambda x: x['target'] in x['anchor'], axis=1).astype('int8')\n",
    "\n",
    "        df['anchor_word_isin_target'] = df[['anchor_word_set', 'target_word_set']].apply(\n",
    "            lambda x: x['anchor_word_set'].issubset(x['target_word_set']), axis=1).astype('int8')\n",
    "        df['target_word_isin_anchor'] = df[['anchor_word_set', 'target_word_set']].apply(\n",
    "            lambda x: x['target_word_set'].issubset(x['anchor_word_set']), axis=1).astype('int8')\n",
    "\n",
    "        df['first_word_issame'] = (df['anchor_first_word'] == df['target_first_word']).astype('int8')\n",
    "        df['last_word_issame'] = (df['anchor_last_word'] == df['target_last_word']).astype('int8')\n",
    "        \n",
    "        word_cnt_dict = {}\n",
    "        lists = df['anchor_word_list'].values.tolist() + df['target_word_list'].values.tolist()\n",
    "        for l in tqdm(lists):\n",
    "            for w in l:\n",
    "                if w not in word_cnt_dict.keys():\n",
    "                    word_cnt_dict[w] = 0\n",
    "                word_cnt_dict[w] += 1\n",
    "\n",
    "        df['anchor_word_cnt_list'] = df['anchor_word_list'].apply(lambda x: [word_cnt_dict[c] for c in x])\n",
    "        df['anchor_word_cnt_max'] = df['anchor_word_cnt_list'].apply(np.max)\n",
    "        df['anchor_word_cnt_min'] = df['anchor_word_cnt_list'].apply(np.min)\n",
    "        df['anchor_word_cnt_mean'] = df['anchor_word_cnt_list'].apply(np.mean)\n",
    "        df['anchor_word_cnt_sum'] = df['anchor_word_cnt_list'].apply(np.sum)\n",
    "        df['anchor_word_cnt_std'] = df['anchor_word_cnt_list'].apply(np.std)\n",
    "\n",
    "        df['target_word_cnt_list'] = df['target_word_list'].apply(lambda x: [word_cnt_dict[c] for c in x])\n",
    "        df['target_word_cnt_max'] = df['target_word_cnt_list'].apply(np.max)\n",
    "        df['target_word_cnt_min'] = df['target_word_cnt_list'].apply(np.min)\n",
    "        df['target_word_cnt_mean'] = df['target_word_cnt_list'].apply(np.mean)\n",
    "        df['target_word_cnt_sum'] = df['target_word_cnt_list'].apply(np.sum)\n",
    "        df['target_word_cnt_std'] = df['target_word_cnt_list'].apply(np.std)\n",
    "\n",
    "        df['word_cnt_sum_ratio'] = df['anchor_word_cnt_sum'] / df['target_word_cnt_sum']\n",
    "\n",
    "        del word_cnt_dict, lists\n",
    "        \n",
    "        df['word_combine_list'] = df[['anchor_word_list', 'target_word_list']].apply(\n",
    "            lambda x: combine(x['anchor_word_list'], x['target_word_list']), axis=1)\n",
    "\n",
    "        word_combine_cnt_dict = {}\n",
    "        lists = df['word_combine_list'].values.tolist()\n",
    "        for l in tqdm(lists):\n",
    "            for w in l:\n",
    "                if w not in word_combine_cnt_dict.keys():\n",
    "                    word_combine_cnt_dict[w] = 0\n",
    "                word_combine_cnt_dict[w] += 1\n",
    "\n",
    "        df['word_combine_cnt_list'] = df['word_combine_list'].apply(lambda x: [word_combine_cnt_dict[c] for c in x])\n",
    "        df['word_combine_cnt_max'] = df['word_combine_cnt_list'].apply(np.max)\n",
    "        df['word_combine_cnt_min'] = df['word_combine_cnt_list'].apply(np.min)\n",
    "        df['word_combine_cnt_median'] = df['word_combine_cnt_list'].apply(np.median)\n",
    "        df['word_combine_cnt_mean'] = df['word_combine_cnt_list'].apply(np.mean)\n",
    "        df['word_combine_cnt_sum'] = df['word_combine_cnt_list'].apply(np.sum)\n",
    "        df['word_combine_cnt_std'] = df['word_combine_cnt_list'].apply(np.std)\n",
    "\n",
    "        del word_combine_cnt_dict, lists\n",
    "        \n",
    "        for f in tqdm([\n",
    "            'anchor_char_list', 'anchor_word_list', 'target_char_list', 'target_word_list',\n",
    "            'anchor_char_set', 'anchor_word_set', 'target_char_set', 'target_word_set',\n",
    "            'anchor_word_cnt_list', 'target_word_cnt_list', 'word_combine_list', 'word_combine_cnt_list',\n",
    "            'char_common_prefix', 'char_common_suffix', 'char_LCStr',\n",
    "            'word_common_prefix', 'word_common_suffix', 'word_LCStr',\n",
    "        ]):\n",
    "            del df[f]\n",
    "        \n",
    "        for f in tqdm(cate_cols):\n",
    "            uniq = df[df[f].notna()][f].unique()\n",
    "            df[f] = df[f].map(dict(zip(uniq, range(len(uniq)))))\n",
    "        \n",
    "        X = df[df['tag'] == 0].reset_index(drop=True)\n",
    "        X_test = df[df['tag'] == 1].reset_index(drop=True)\n",
    "        \n",
    "        for f in tqdm([\n",
    "            ['anchor_first_word'],\n",
    "            ['anchor_last_word'],\n",
    "            ['target_first_word'],\n",
    "            ['target_last_word'],\n",
    "            ['anchor_first_word', 'target_first_word'],\n",
    "            ['anchor_last_word', 'target_last_word'],\n",
    "            ['anchor_first_word', 'anchor_last_word'],\n",
    "            ['target_first_word', 'target_last_word'],\n",
    "        ]):\n",
    "            enc_field = f'{\"_\".join(f)}_target_mean'\n",
    "            X[enc_field] = 0\n",
    "            X_test[enc_field] = 0\n",
    "            for i in range(FOLD):\n",
    "                val_idx = X[X['fold'] == i].index\n",
    "                trn_idx = X[X['fold'] != i].index\n",
    "\n",
    "                trn_x = X.iloc[trn_idx].reset_index(drop=True)\n",
    "                val_x = X[f].iloc[val_idx].reset_index(drop=True)\n",
    "                test_copy = X_test[f].copy()\n",
    "\n",
    "                trn_x[enc_field] = trn_x.groupby(f)['score'].transform('mean')\n",
    "                m = trn_x[f + [enc_field]].drop_duplicates(f).reset_index(drop=True)\n",
    "                val_x = val_x.merge(m, on=f, how='left')\n",
    "                val_x[enc_field] = val_x[enc_field].fillna(X['score'].mean())\n",
    "                X.loc[val_idx, enc_field] = val_x[enc_field].values\n",
    "                test_copy = test_copy.merge(m, on=f, how='left')\n",
    "                test_copy[enc_field] = test_copy[enc_field].fillna(X['score'].mean())\n",
    "                X_test[enc_field] += test_copy[enc_field].values / FOLD\n",
    "        \n",
    "        return X, X_test\n",
    "    \n",
    "    \n",
    "    X, X_test = feat_eng_core(train_data, test_data)\n",
    "    cols = [\n",
    "        f for f in X.columns if f not in ['id', 'anchor', 'target', 'score', 'tag', 'fold', 'bert_proba']\n",
    "    ]\n",
    "    X['tree_proba'] = 0\n",
    "    X_test['tree_proba'] = 0\n",
    "    clf = LGBMRegressor(\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,\n",
    "        n_estimators=3000,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=2022,\n",
    "        n_jobs=10,\n",
    "        metric='None'\n",
    "    )\n",
    "    for i in range(FOLD):\n",
    "        print(f'lgbm --------------------- {i} fold ---------------------')\n",
    "        t = time.time()\n",
    "        val_idx = X[X['fold'] == i].index\n",
    "        trn_idx = X[X['fold'] != i].index\n",
    "        ic(val_idx, trn_idx)\n",
    "        trn_x = X.iloc[trn_idx].reset_index(drop=True)\n",
    "        val_x = X.iloc[val_idx].reset_index(drop=True)\n",
    "        ic(trn_x.shape, val_x.shape)\n",
    "        clf.fit(\n",
    "            trn_x[cols], trn_x['score'],\n",
    "            eval_set=[(val_x[cols], val_x['score'])],\n",
    "            eval_metric='l1',\n",
    "            early_stopping_rounds=300,\n",
    "            verbose=300\n",
    "        )\n",
    "        X.loc[val_idx, 'tree_proba'] = clf.predict(val_x[cols])\n",
    "        X_test['tree_proba'] += clf.predict(X_test[cols]) / FOLD\n",
    "        print(f'runtime: {time.time() - t}\\n')\n",
    "    \n",
    "    cols = ['bert_proba', 'tree_proba']\n",
    "    X['stacking_proba'] = 0\n",
    "    X_test['stacking_proba'] = 0\n",
    "    clf = BayesianRidge()\n",
    "    for i in range(FOLD):\n",
    "        print(f'ridge --------------------- {i} fold ---------------------')\n",
    "        t = time.time()\n",
    "        val_idx = X[X['fold'] == i].index\n",
    "        trn_idx = X[X['fold'] != i].index\n",
    "        trn_x = X.iloc[trn_idx].reset_index(drop=True)\n",
    "        val_x = X.iloc[val_idx].reset_index(drop=True)\n",
    "        clf.fit(trn_x[cols], trn_x['score'])\n",
    "        X.loc[val_idx, 'stacking_proba'] += clf.predict(val_x[cols])\n",
    "        X_test['stacking_proba'] += clf.predict(X_test[cols]) / FOLD\n",
    "        print(f'runtime: {time.time() - t}\\n')\n",
    "    \n",
    "    return X[['id', 'score', 'bert_proba', 'tree_proba', 'stacking_proba']], X_test[['id', 'bert_proba', 'tree_proba', 'stacking_proba']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/24/22 17:36:09] 1786042895.py:2 in <module>\n",
      "                    x_train.columns: Index(['id', 'anchor', 'target', 'context', 'fold', 'bert_proba', 'score'], dtype='object')\n",
      "[06/24/22 17:36:09] 1786042895.py:6 in <module>\n",
      "                    x_test.columns: Index(['id', 'anchor', 'target', 'context', 'bert_proba'], dtype='object')\n",
      "100%|██████████| 2/2 [00:00<00:00, 82.78it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 398.83it/s]\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.70s/it]\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.01s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.00it/s]\n",
      "100%|██████████| 145892/145892 [00:00<00:00, 1268260.50it/s]\n",
      "100%|██████████| 72946/72946 [00:00<00:00, 581819.06it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 708.28it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 14.23it/s]\n",
      "100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\n",
      "[06/24/22 17:37:29] 3007469764.py:317 in run_stacking()\n",
      "                    val_idx: Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
      "                                         ...\n",
      "                                         7183, 7184, 7185, 7186, 7187, 7188, 7189, 7190, 7191, 7192],\n",
      "                                        dtype='int64', length=7193)\n",
      "                    trn_idx: Int64Index([ 7193,  7194,  7195,  7196,  7197,  7198,  7199,  7200,  7201,\n",
      "                                          7202,\n",
      "                                         ...\n",
      "                                         36463, 36464, 36465, 36466, 36467, 36468, 36469, 36470, 36471,\n",
      "                                         36472],\n",
      "                                        dtype='int64', length=29280)\n",
      "[06/24/22 17:37:29] 3007469764.py:320 in run_stacking()\n",
      "                    trn_x.shape: (29280, 101)\n",
      "                    val_x.shape: (7193, 101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm --------------------- 0 fold ---------------------\n",
      "[300]\tvalid_0's l1: 0.141532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/24/22 17:37:31] 3007469764.py:317 in run_stacking()\n",
      "                    val_idx: Int64Index([ 7193,  7194,  7195,  7196,  7197,  7198,  7199,  7200,  7201,\n",
      "                                          7202,\n",
      "                                         ...\n",
      "                                         14439, 14440, 14441, 14442, 14443, 14444, 14445, 14446, 14447,\n",
      "                                         14448],\n",
      "                                        dtype='int64', length=7256)\n",
      "                    trn_idx: Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                                             9,\n",
      "                                         ...\n",
      "                                         36463, 36464, 36465, 36466, 36467, 36468, 36469, 36470, 36471,\n",
      "                                         36472],\n",
      "                                        dtype='int64', length=29217)\n",
      "[06/24/22 17:37:31] 3007469764.py:320 in run_stacking()\n",
      "                    trn_x.shape: (29217, 101)\n",
      "                    val_x.shape: (7256, 101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.4622762203216553\n",
      "\n",
      "lgbm --------------------- 1 fold ---------------------\n",
      "[300]\tvalid_0's l1: 0.142313\n",
      "[600]\tvalid_0's l1: 0.142532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/24/22 17:37:33] 3007469764.py:317 in run_stacking()\n",
      "                    val_idx: Int64Index([14449, 14450, 14451, 14452, 14453, 14454, 14455, 14456, 14457,\n",
      "                                         14458,\n",
      "                                         ...\n",
      "                                         21332, 21333, 21334, 21335, 21336, 21337, 21338, 21339, 21340,\n",
      "                                         21341],\n",
      "                                        dtype='int64', length=6893)\n",
      "                    trn_idx: Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                                             9,\n",
      "                                         ...\n",
      "                                         36463, 36464, 36465, 36466, 36467, 36468, 36469, 36470, 36471,\n",
      "                                         36472],\n",
      "                                        dtype='int64', length=29580)\n",
      "[06/24/22 17:37:33] 3007469764.py:320 in run_stacking()\n",
      "                    trn_x.shape: (29580, 101)\n",
      "                    val_x.shape: (6893, 101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.8549184799194336\n",
      "\n",
      "lgbm --------------------- 2 fold ---------------------\n",
      "[300]\tvalid_0's l1: 0.136527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/24/22 17:37:34] 3007469764.py:317 in run_stacking()\n",
      "                    val_idx: Int64Index([21342, 21343, 21344, 21345, 21346, 21347, 21348, 21349, 21350,\n",
      "                                         21351,\n",
      "                                         ...\n",
      "                                         28485, 28486, 28487, 28488, 28489, 28490, 28491, 28492, 28493,\n",
      "                                         28494],\n",
      "                                        dtype='int64', length=7153)\n",
      "                    trn_idx: Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                                             9,\n",
      "                                         ...\n",
      "                                         36463, 36464, 36465, 36466, 36467, 36468, 36469, 36470, 36471,\n",
      "                                         36472],\n",
      "                                        dtype='int64', length=29320)\n",
      "[06/24/22 17:37:34] 3007469764.py:320 in run_stacking()\n",
      "                    trn_x.shape: (29320, 101)\n",
      "                    val_x.shape: (7153, 101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.6139953136444092\n",
      "\n",
      "lgbm --------------------- 3 fold ---------------------\n",
      "[300]\tvalid_0's l1: 0.144738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/24/22 17:37:36] 3007469764.py:317 in run_stacking()\n",
      "                    val_idx: Int64Index([28495, 28496, 28497, 28498, 28499, 28500, 28501, 28502, 28503,\n",
      "                                         28504,\n",
      "                                         ...\n",
      "                                         36463, 36464, 36465, 36466, 36467, 36468, 36469, 36470, 36471,\n",
      "                                         36472],\n",
      "                                        dtype='int64', length=7978)\n",
      "                    trn_idx: Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                                             9,\n",
      "                                         ...\n",
      "                                         28485, 28486, 28487, 28488, 28489, 28490, 28491, 28492, 28493,\n",
      "                                         28494],\n",
      "                                        dtype='int64', length=28495)\n",
      "[06/24/22 17:37:36] 3007469764.py:320 in run_stacking()\n",
      "                    trn_x.shape: (28495, 101)\n",
      "                    val_x.shape: (7978, 101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime: 1.492877721786499\n",
      "\n",
      "lgbm --------------------- 4 fold ---------------------\n",
      "[300]\tvalid_0's l1: 0.141385\n",
      "runtime: 1.1087117195129395\n",
      "\n",
      "ridge --------------------- 0 fold ---------------------\n",
      "runtime: 0.0686333179473877\n",
      "\n",
      "ridge --------------------- 1 fold ---------------------\n",
      "runtime: 0.03560924530029297\n",
      "\n",
      "ridge --------------------- 2 fold ---------------------\n",
      "runtime: 0.03301715850830078\n",
      "\n",
      "ridge --------------------- 3 fold ---------------------\n",
      "runtime: 0.02453446388244629\n",
      "\n",
      "ridge --------------------- 4 fold ---------------------\n",
      "runtime: 0.024599075317382812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.DataFrame(x)\n",
    "ic(x_train.columns)\n",
    "del x['score']\n",
    "del x['fold']\n",
    "x_test = pd.DataFrame(x)\n",
    "ic(x_test.columns)\n",
    "a, b = run_stacking(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bert_proba</th>\n",
       "      <th>tree_proba</th>\n",
       "      <th>stacking_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00068e3dfd5515df</td>\n",
       "      <td>0.252783</td>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.241072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8495ef1763e1</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.105973</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019b063a0fe1dc8</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>0.098650</td>\n",
       "      <td>-0.004335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002230e82321e23c</td>\n",
       "      <td>0.475657</td>\n",
       "      <td>0.532071</td>\n",
       "      <td>0.474224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0022e4c3050cf263</td>\n",
       "      <td>0.994114</td>\n",
       "      <td>1.029632</td>\n",
       "      <td>1.014073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>ffa2cb9b30cc96be</td>\n",
       "      <td>0.330914</td>\n",
       "      <td>0.059384</td>\n",
       "      <td>0.319842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>ffa964af3df23a35</td>\n",
       "      <td>0.533170</td>\n",
       "      <td>0.456617</td>\n",
       "      <td>0.532674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>ffb6e883de7d9d67</td>\n",
       "      <td>0.486388</td>\n",
       "      <td>0.426027</td>\n",
       "      <td>0.484119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>fff0b4d9fca7fae3</td>\n",
       "      <td>0.386951</td>\n",
       "      <td>0.153019</td>\n",
       "      <td>0.378629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>fff8d1ccce8e20ec</td>\n",
       "      <td>0.032047</td>\n",
       "      <td>0.051222</td>\n",
       "      <td>0.011704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  bert_proba  tree_proba  stacking_proba\n",
       "0      00068e3dfd5515df    0.252783    0.219812        0.241072\n",
       "1      000c8495ef1763e1    0.023997    0.105973        0.004008\n",
       "2      0019b063a0fe1dc8    0.015981    0.098650       -0.004335\n",
       "3      002230e82321e23c    0.475657    0.532071        0.474224\n",
       "4      0022e4c3050cf263    0.994114    1.029632        1.014073\n",
       "...                 ...         ...         ...             ...\n",
       "36468  ffa2cb9b30cc96be    0.330914    0.059384        0.319842\n",
       "36469  ffa964af3df23a35    0.533170    0.456617        0.532674\n",
       "36470  ffb6e883de7d9d67    0.486388    0.426027        0.484119\n",
       "36471  fff0b4d9fca7fae3    0.386951    0.153019        0.378629\n",
       "36472  fff8d1ccce8e20ec    0.032047    0.051222        0.011704\n",
       "\n",
       "[36473 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>bert_proba</th>\n",
       "      <th>tree_proba</th>\n",
       "      <th>stacking_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00068e3dfd5515df</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.252783</td>\n",
       "      <td>0.238936</td>\n",
       "      <td>0.242448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8495ef1763e1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.204718</td>\n",
       "      <td>0.005986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019b063a0fe1dc8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>0.218664</td>\n",
       "      <td>-0.002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002230e82321e23c</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.475657</td>\n",
       "      <td>0.533760</td>\n",
       "      <td>0.475542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0022e4c3050cf263</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.994114</td>\n",
       "      <td>0.997540</td>\n",
       "      <td>1.015442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>ffa2cb9b30cc96be</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.330914</td>\n",
       "      <td>0.201467</td>\n",
       "      <td>0.320080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>ffa964af3df23a35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.533170</td>\n",
       "      <td>0.431948</td>\n",
       "      <td>0.531520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>ffb6e883de7d9d67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.486388</td>\n",
       "      <td>0.359960</td>\n",
       "      <td>0.482317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>fff0b4d9fca7fae3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.386951</td>\n",
       "      <td>0.127218</td>\n",
       "      <td>0.376468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>fff8d1ccce8e20ec</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.032047</td>\n",
       "      <td>0.159882</td>\n",
       "      <td>0.012390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  score  bert_proba  tree_proba  stacking_proba\n",
       "0      00068e3dfd5515df   0.25    0.252783    0.238936        0.242448\n",
       "1      000c8495ef1763e1   0.00    0.023997    0.204718        0.005986\n",
       "2      0019b063a0fe1dc8   0.00    0.015981    0.218664       -0.002140\n",
       "3      002230e82321e23c   0.50    0.475657    0.533760        0.475542\n",
       "4      0022e4c3050cf263   1.00    0.994114    0.997540        1.015442\n",
       "...                 ...    ...         ...         ...             ...\n",
       "36468  ffa2cb9b30cc96be   0.00    0.330914    0.201467        0.320080\n",
       "36469  ffa964af3df23a35   0.50    0.533170    0.431948        0.531520\n",
       "36470  ffb6e883de7d9d67   0.50    0.486388    0.359960        0.482317\n",
       "36471  fff0b4d9fca7fae3   0.25    0.386951    0.127218        0.376468\n",
       "36472  fff8d1ccce8e20ec   0.00    0.032047    0.159882        0.012390\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>fold</th>\n",
       "      <th>bert_proba</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00068e3dfd5515df</td>\n",
       "      <td>conductor particles</td>\n",
       "      <td>resin cores</td>\n",
       "      <td>B01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.252783</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8495ef1763e1</td>\n",
       "      <td>page file</td>\n",
       "      <td>hidden camera</td>\n",
       "      <td>G09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023997</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019b063a0fe1dc8</td>\n",
       "      <td>predetermined acceleration</td>\n",
       "      <td>predetermined policy</td>\n",
       "      <td>B66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002230e82321e23c</td>\n",
       "      <td>indoor room</td>\n",
       "      <td>air conditioning room</td>\n",
       "      <td>F24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475657</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0022e4c3050cf263</td>\n",
       "      <td>tap portion</td>\n",
       "      <td>tap portion</td>\n",
       "      <td>B23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994114</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>ffa2cb9b30cc96be</td>\n",
       "      <td>cement composite</td>\n",
       "      <td>organic binders</td>\n",
       "      <td>C04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.330914</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>ffa964af3df23a35</td>\n",
       "      <td>extend areas</td>\n",
       "      <td>extend area housing</td>\n",
       "      <td>H01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.533170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>ffb6e883de7d9d67</td>\n",
       "      <td>water propulsion device</td>\n",
       "      <td>propulsion unit</td>\n",
       "      <td>B63</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486388</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>fff0b4d9fca7fae3</td>\n",
       "      <td>high gradient magnetic separators</td>\n",
       "      <td>magnetic equipment</td>\n",
       "      <td>C02</td>\n",
       "      <td>4</td>\n",
       "      <td>0.386951</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>fff8d1ccce8e20ec</td>\n",
       "      <td>perform working operations</td>\n",
       "      <td>psychology of working framework</td>\n",
       "      <td>B23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                             anchor  \\\n",
       "0      00068e3dfd5515df                conductor particles   \n",
       "1      000c8495ef1763e1                          page file   \n",
       "2      0019b063a0fe1dc8         predetermined acceleration   \n",
       "3      002230e82321e23c                        indoor room   \n",
       "4      0022e4c3050cf263                        tap portion   \n",
       "...                 ...                                ...   \n",
       "36468  ffa2cb9b30cc96be                   cement composite   \n",
       "36469  ffa964af3df23a35                       extend areas   \n",
       "36470  ffb6e883de7d9d67            water propulsion device   \n",
       "36471  fff0b4d9fca7fae3  high gradient magnetic separators   \n",
       "36472  fff8d1ccce8e20ec         perform working operations   \n",
       "\n",
       "                                target context  fold  bert_proba  score  tag  \n",
       "0                          resin cores     B01     0    0.252783   0.25    0  \n",
       "1                        hidden camera     G09     0    0.023997   0.00    0  \n",
       "2                 predetermined policy     B66     0    0.015981   0.00    0  \n",
       "3                air conditioning room     F24     0    0.475657   0.50    0  \n",
       "4                          tap portion     B23     0    0.994114   1.00    0  \n",
       "...                                ...     ...   ...         ...    ...  ...  \n",
       "36468                  organic binders     C04     4    0.330914   0.00    0  \n",
       "36469              extend area housing     H01     4    0.533170   0.50    0  \n",
       "36470                  propulsion unit     B63     4    0.486388   0.50    0  \n",
       "36471               magnetic equipment     C02     4    0.386951   0.25    0  \n",
       "36472  psychology of working framework     B23     4    0.032047   0.00    0  \n",
       "\n",
       "[36473 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8682403177522899"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(a.score, a.bert_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681291501732962"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(a.score, a.stacking_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
